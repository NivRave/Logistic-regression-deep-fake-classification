# Logistic-regression-deep-fake-classification
A Logistic regression model built from scratch that classifies input images as real/fake with high accuracy
"<h2>Readme</h2>\n",
    "The following project is our implementation of the Logistic Regression classification with Gradient Descent model.</br>\n",
    "The used dataset contains 1000 images sized 1024X1024, divided to 500 'Real' and 500 'Fake' images </br>\n",
    "and labled accordingly. The goal of the project is to be able to classify new images as real or fake using</br>\n",
    "the properties achieved during the learning process.</br>\n",
    "The model was built from scratch and the code contains the implementation of all the used calculations,</br>\n",
    "without any ML/AI external libraries. We used Open-CV to process the dataset images, Pandas and Numpy for</br>\n",
    "convenient storage and usage of data structures, seaborn and matplotlib.pyplot for the plots and graphical endpoints</br>\n",
    "and os for operaing system related actions.</br>\n",
    "The notebook contains different sections, each has a header that describes the following cells and their responesbility</br>\n",
    "and inside comments that describe the micro responsebilities and implementations.</br>\n",
    "The first few cells contain different utilities for plotting and data handling.</br>\n",
    "The following cells contain the Logistic Regression model's different functions and utilities, including</br>\n",
    "algorithms and optimization functions.</br>\n",
    "The last cells contain the concrete model's implementation and import/export functions to fasten and ease the</br>\n",
    "model's handling.</br>\n",
    "</br>\n",
    "<b>Regarding the model itself and the ways to initialize the model, we suggest 4 options:</b></br>\n",
    "1. Complete learning using pre-defined (optimal and efficient values we found) learning rate and iterations.</br>\n",
    "2. Complete learning with an algorithm to find the optimal learning rate and iterations.</br>\n",
    "3. Initialization through import - importing our existing model, attached in the 'model.npy' file.</br>\n",
    "4. Initialization of an empty model.</br>\n",
    "</br>\n",
    "Each initialization/creation method will affect the time to it takes to initialize, the amount of resources</br>\n",
    "the project will use in the process and the accuracy.</br>\n",
    "</br>\n",
    "The data is tagged as 'Real'=0, 'Fake'=1 and located inside matching folders in a './data' folder in the root of the</br>\n",
    "notebook (watch the matching functions' documentaion for more information).</br>\n",
    "</br>\n",
    "The calculated coefficients are found at model.w_vector for the coefficients vector (sorted by iterations)</br>\n",
    "or model.wm for the last iteration's coefficients, those to whom the model has converged. Use the import/export</br>\n",
    "functions to import/export the coefficients for later usage.</br>\n",
    "</br>\n",
    "To run a test on new data, place the data in a './data/FutureData' folder in the root of the notebook (watch the matching</br> functions' documentaion for more information).</br>\n",
    "After placing the data, activate model.test() method to view the classification results.</br>\n",
    "The results will be written to a 'FutureDataEstimatedLabels.csv' file in the root of the notebook (watch the matching</br> functions' documentaion for more information).</br>"
   ]
